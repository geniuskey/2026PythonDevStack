# pandas ì™„ë²½ ê°€ì´ë“œ

> **ë°ì´í„° ë¶„ì„ì˜ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**

â­ **2026 ì¶”ì²œ** | ğŸ“Š ë°ì´í„° ë¶„ì„ | ğŸ¼ ì‚¬ì‹¤ìƒ í‘œì¤€ | ğŸ”— ë°©ëŒ€í•œ ìƒíƒœê³„

---

## ê°œìš”

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ê³µì‹ ì‚¬ì´íŠ¸** | https://pandas.pydata.org |
| **GitHub** | https://github.com/pandas-dev/pandas |
| **ì²« ë¦´ë¦¬ì¦ˆ** | 2008ë…„ |
| **ë¼ì´ì„ ìŠ¤** | BSD |

### í•œ ì¤„ ìš”ì•½

**ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•œ íŒŒì´ì¬ì˜ ì‚¬ì‹¤ìƒ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**

---

## ì™œ pandasì¸ê°€

```python
# NumPyë§Œìœ¼ë¡œëŠ” ë¶€ì¡±
import numpy as np
data = np.array([[1, 2], [3, 4]])  # ë‹¨ìˆœ ë°°ì—´, ì»¬ëŸ¼ëª… ì—†ìŒ

# pandasëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„°
import pandas as pd
df = pd.DataFrame({
    'name': ['Alice', 'Bob'],
    'age': [25, 30]
})
# ì»¬ëŸ¼ëª…, ì¸ë±ìŠ¤, íƒ€ì…, ë©”íƒ€ë°ì´í„° ëª¨ë‘ í¬í•¨
```

---

## í•µì‹¬ ìë£Œêµ¬ì¡°

```mermaid
graph TB
    A[pandas ìë£Œêµ¬ì¡°] --> B[Series<br/>1ì°¨ì›<br/>ë‹¨ì¼ ì»¬ëŸ¼]
    A --> C[DataFrame<br/>2ì°¨ì›<br/>í…Œì´ë¸”]

    B --> D[Index<br/>í–‰ ë ˆì´ë¸”]
    C --> D
    C --> E[Columns<br/>ì—´ ë ˆì´ë¸”]

    style C fill:#4CAF50
```

---

## ê¸°ë³¸ ì‚¬ìš©ë²•

### DataFrame ìƒì„±

```python
import pandas as pd

# Dictì—ì„œ
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['NYC', 'LA', 'SF']
})

# CSVì—ì„œ
df = pd.read_csv('data.csv')

# Excelì—ì„œ
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# SQLì—ì„œ
import sqlalchemy as sa
engine = sa.create_engine('postgresql://...')
df = pd.read_sql('SELECT * FROM users', engine)

# JSONì—ì„œ
df = pd.read_json('data.json')
```

### ê¸°ë³¸ ì¡°ì‘

```python
# ë°ì´í„° í™•ì¸
df.head()          # ì²˜ìŒ 5í–‰
df.tail()          # ë§ˆì§€ë§‰ 5í–‰
df.info()          # ë°ì´í„° íƒ€ì…, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
df.describe()      # í†µê³„ ìš”ì•½

# ì„ íƒ
df['name']         # ë‹¨ì¼ ì»¬ëŸ¼ (Series)
df[['name', 'age']]  # ì—¬ëŸ¬ ì»¬ëŸ¼ (DataFrame)
df.loc[0]          # í–‰ ì„ íƒ (ë ˆì´ë¸” ê¸°ì¤€)
df.iloc[0]         # í–‰ ì„ íƒ (ìœ„ì¹˜ ê¸°ì¤€)

# í•„í„°ë§
df[df['age'] > 25]
df[(df['age'] > 25) & (df['city'] == 'NYC')]

# ì •ë ¬
df.sort_values('age', ascending=False)
df.sort_values(['city', 'age'])
```

---

## ì‹¤ì „ íŒ¨í„´ 10ê°€ì§€

### íŒ¨í„´ 1: ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
# ê²°ì¸¡ì¹˜ í™•ì¸
df.isnull().sum()

# ê²°ì¸¡ì¹˜ ì œê±°
df.dropna()                    # ê²°ì¸¡ì¹˜ ìˆëŠ” í–‰ ì œê±°
df.dropna(subset=['age'])      # íŠ¹ì • ì»¬ëŸ¼ ê¸°ì¤€

# ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
df.fillna(0)                   # 0ìœ¼ë¡œ ì±„ìš°ê¸°
df['age'].fillna(df['age'].mean())  # í‰ê· ìœ¼ë¡œ
df.fillna(method='ffill')      # ì• ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
```

### íŒ¨í„´ 2: ê·¸ë£¹í™” & ì§‘ê³„

```python
# ê·¸ë£¹ë³„ ì§‘ê³„
df.groupby('city')['age'].mean()
df.groupby('city').agg({
    'age': ['mean', 'max', 'min'],
    'salary': 'sum'
})

# ì—¬ëŸ¬ ì»¬ëŸ¼ ê·¸ë£¹í™”
df.groupby(['city', 'department'])['salary'].mean()
```

### íŒ¨í„´ 3: ë³‘í•© & ì¡°ì¸

```python
# ë‘ DataFrame ë³‘í•©
df1 = pd.DataFrame({'id': [1, 2], 'name': ['Alice', 'Bob']})
df2 = pd.DataFrame({'id': [1, 2], 'age': [25, 30]})

# Inner join
pd.merge(df1, df2, on='id')

# Left join
pd.merge(df1, df2, on='id', how='left')

# ì¸ë±ìŠ¤ ê¸°ì¤€ ì¡°ì¸
df1.join(df2, how='inner')
```

### íŒ¨í„´ 4: Pivot & Melt

```python
# Wide to Long (melt)
df_long = df.melt(
    id_vars=['id', 'name'],
    value_vars=['q1', 'q2', 'q3'],
    var_name='quarter',
    value_name='sales'
)

# Long to Wide (pivot)
df_wide = df_long.pivot(
    index='name',
    columns='quarter',
    values='sales'
)

# Pivot table (with aggregation)
df.pivot_table(
    values='sales',
    index='name',
    columns='quarter',
    aggfunc='sum'
)
```

### íŒ¨í„´ 5: ì‹œê³„ì—´ ë°ì´í„°

```python
# ë‚ ì§œ íŒŒì‹±
df['date'] = pd.to_datetime(df['date'])

# ë‚ ì§œ ì¸ë±ìŠ¤
df.set_index('date', inplace=True)

# ë¦¬ìƒ˜í”Œë§
df.resample('M').mean()  # ì›”ë³„ í‰ê· 
df.resample('W').sum()   # ì£¼ë³„ í•©ê³„

# ë‚ ì§œ ë²”ìœ„ ìƒì„±
dates = pd.date_range('2024-01-01', periods=365, freq='D')

# ë‚ ì§œ ì»´í¬ë„ŒíŠ¸ ì¶”ì¶œ
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['dayofweek'] = df['date'].dt.dayofweek
```

### íŒ¨í„´ 6: Apply & Lambda

```python
# ë‹¨ì¼ ì»¬ëŸ¼ì— í•¨ìˆ˜ ì ìš©
df['age_group'] = df['age'].apply(lambda x: 'adult' if x >= 18 else 'minor')

# í–‰ë³„ ì ìš©
df['full_name'] = df.apply(
    lambda row: f"{row['first_name']} {row['last_name']}",
    axis=1
)

# ë²¡í„°í™” ì—°ì‚° (ë” ë¹ ë¦„)
df['age_doubled'] = df['age'] * 2  # applyë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„
```

### íŒ¨í„´ 7: ë¬¸ìì—´ ì²˜ë¦¬

```python
# ëŒ€ì†Œë¬¸ì ë³€í™˜
df['name'] = df['name'].str.lower()

# íŒ¨í„´ ë§¤ì¹­
df[df['email'].str.contains('@gmail.com')]

# ë¬¸ìì—´ ë¶„í• 
df[['first_name', 'last_name']] = df['name'].str.split(' ', expand=True)

# ì¹˜í™˜
df['text'] = df['text'].str.replace('old', 'new')
```

### íŒ¨í„´ 8: ì¹´í…Œê³ ë¦¬ íƒ€ì…

```python
# ë©”ëª¨ë¦¬ ì ˆì•½
df['city'] = df['city'].astype('category')

# ì¹´í…Œê³ ë¦¬ ì •ë³´
df['city'].cat.categories
df['city'].value_counts()

# ìˆœì„œ ìˆëŠ” ì¹´í…Œê³ ë¦¬
df['size'] = pd.Categorical(
    df['size'],
    categories=['S', 'M', 'L', 'XL'],
    ordered=True
)
```

### íŒ¨í„´ 9: Window Functions

```python
# ì´ë™ í‰ê· 
df['ma_7'] = df['value'].rolling(window=7).mean()

# ëˆ„ì  í•©ê³„
df['cumsum'] = df['value'].cumsum()

# ê·¸ë£¹ë³„ ìœˆë„ìš°
df['group_rank'] = df.groupby('category')['value'].rank()
```

### íŒ¨í„´ 10: ë©€í‹°ì¸ë±ìŠ¤

```python
# ë©€í‹°ì¸ë±ìŠ¤ ìƒì„±
df.set_index(['city', 'year'], inplace=True)

# íŠ¹ì • ë ˆë²¨ ì„ íƒ
df.loc[('NYC', 2023)]

# ë ˆë²¨ë³„ ì§‘ê³„
df.groupby(level=0).mean()  # city ë ˆë²¨

# ì¸ë±ìŠ¤ ë¦¬ì…‹
df.reset_index()
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ë²¡í„°í™” ì—°ì‚° ì‚¬ìš©

```python
# ë‚˜ì¨: ëŠë¦¼
for i in range(len(df)):
    df.loc[i, 'new_col'] = df.loc[i, 'col1'] * 2

# ì¢‹ìŒ: ë¹ ë¦„
df['new_col'] = df['col1'] * 2
```

### 2. Dtype ìµœì í™”

```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
df.memory_usage(deep=True)

# íƒ€ì… ìµœì í™”
df['age'] = df['age'].astype('int8')  # int64 â†’ int8
df['category'] = df['category'].astype('category')

# ë‹¤ìš´ìºìŠ¤íŠ¸
df = df.apply(pd.to_numeric, downcast='integer')
```

### 3. Chunk ì²˜ë¦¬

```python
# ëŒ€ìš©ëŸ‰ íŒŒì¼
chunks = pd.read_csv('huge.csv', chunksize=10000)

result = []
for chunk in chunks:
    processed = chunk[chunk['value'] > 100]
    result.append(processed)

df = pd.concat(result)
```

---

## pandas vs polars

| íŠ¹ì§• | pandas | polars |
|------|--------|--------|
| ì†ë„ | ê¸°ì¤€ | 10ë°° ë¹ ë¦„ |
| ë©”ëª¨ë¦¬ | ë§ìŒ | íš¨ìœ¨ì  |
| ìƒíƒœê³„ | ê±°ëŒ€í•¨ | ì„±ì¥ ì¤‘ |
| í•™ìŠµ ê³¡ì„  | ë‚®ìŒ | ì¤‘ê°„ |

**pandas ì„ íƒ:**
- ìƒíƒœê³„ ì˜ì¡´ì„± (sklearn, scipy)
- ë³µì¡í•œ ë°ì´í„° ë³€í™˜
- ì‘ì€ ë°ì´í„° (~1GB)

**polars ì„ íƒ:**
- ëŒ€ìš©ëŸ‰ ë°ì´í„°
- ì„±ëŠ¥ ì¤‘ìš”
- ìƒˆ í”„ë¡œì íŠ¸

---

## ì‹¤ì „ ì˜ˆì œ

```python
import pandas as pd

# 1. ë°ì´í„° ë¡œë“œ
df = pd.read_csv('sales.csv', parse_dates=['date'])

# 2. ë°ì´í„° ì •ì œ
df = df.dropna(subset=['amount'])
df = df[df['amount'] > 0]

# 3. ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month

# 4. ì§‘ê³„
monthly_sales = df.groupby(['year', 'month']).agg({
    'amount': 'sum',
    'order_id': 'count'
}).rename(columns={'order_id': 'order_count'})

# 5. í”¼ë²—
sales_pivot = df.pivot_table(
    values='amount',
    index='product',
    columns='month',
    aggfunc='sum',
    fill_value=0
)

# 6. ì €ì¥
monthly_sales.to_csv('monthly_report.csv')
sales_pivot.to_excel('pivot_report.xlsx')
```

---

**[â† ë°ì´í„° ì²˜ë¦¬](../../04-library-catalog/data-science/README.md)** | **[ë‹¤ìŒ: httpx â†’](../networking/httpx.md)**
